<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Omanshu&#39;s blog</title>
    <link>http://omanshuthapliyal.github.io/blog/posts/</link>
    <description>Recent content in Posts on Omanshu&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Sep 2019 10:27:01 -0400</lastBuildDate>
    
	<atom:link href="http://omanshuthapliyal.github.io/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>MLP Approximation</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/mlp-approximation/</link>
      <pubDate>Thu, 12 Sep 2019 10:27:01 -0400</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/mlp-approximation/</guid>
      <description>Almost always we hear about classification or machine learning problems, the go-to methods to solve the problem are neural networks, or multi-layered percetrons (MLP). Now function approximation problems, which is what classification is, are very well defined in terms of consistency, accuracy, and other abilities of the approximator. Why are MLPs then able to approximate functions well? Especially given the fact that most of the problems in coming up with candidate architectures, activation functions, etc.</description>
    </item>
    
    <item>
      <title>Birds and Frogs in Science</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/birds-and-frogs/</link>
      <pubDate>Sun, 25 Aug 2019 20:20:44 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/birds-and-frogs/</guid>
      <description>One of my fellow grad students shared a paper with me that turned out to be a great read. It was Professor Freeman Dyson&#39;s article titled Birds and Frogs, that was the invited Einstein lecture at the American Mathematical Society. Dyson talks about two categories of mathematicians (researchers) -- birds, and frogs. While birds soar high, and get a view of the entire landscape, frogs tread tread deep, looking for details.</description>
    </item>
    
    <item>
      <title>Real Analysis Notes</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/my-real-notes/</link>
      <pubDate>Sat, 24 Aug 2019 23:38:20 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/my-real-notes/</guid>
      <description>When I took the course on Real Analysis, it made me very nervous. I was having fever dreams from the past when I took undergraduate real analysis and the epsilon-delta definitions just did not make a lot of sense. In retrospect, taking MA504 has been one of the best academic decisions, especially as an engineer.
It has helped me a lot in how to concretely formulate definitions, and what &amp;lsquo;approaching&amp;rsquo;, &amp;lsquo;tending&amp;rsquo;, &amp;lsquo;limiting&amp;rsquo;, and other weasel words mean in a mathematical sense.</description>
    </item>
    
    <item>
      <title>ML SoTA Resources</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/ml-sota/</link>
      <pubDate>Sun, 18 Aug 2019 22:36:00 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/ml-sota/</guid>
      <description>The internet is filled with machine learning resources, and one of the most annoying things about them is the sheer volume. There are many attempts at making compilations of papers, code, and current status quo in the vastly active, and fast paced field. This post is to serve as a collection of my own where I will only post state of the art in machine learning.
Most of these links are updated frequently and maintained by the community, and I have collected these only for reference.</description>
    </item>
    
    <item>
      <title>But why is Compactness important?</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/compactness2/</link>
      <pubDate>Thu, 15 Aug 2019 01:34:25 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/compactness2/</guid>
      <description>In my last post I touched upon the intuition behind topological compactness. We as engineers often hear about the word &#39;compact&#39; as a soft gatekeeping tool from doing serious mathematics. In this post we see why the understanding is very important for doing any mathematics, especially as engineers.
Recall the open cover definition of a compact set as the existence of a finite open subcover for any given open cover of the set.</description>
    </item>
    
    <item>
      <title>Compactness</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/compactness/</link>
      <pubDate>Sat, 10 Aug 2019 15:44:20 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/compactness/</guid>
      <description>This is a non-mathematical note on what I understand about compactness and what it means for a set or a space to be compact. The open cover definition is one that can be found in any textbook, but what does it mean for a set to be compact? Why are such sets called compact? And how do compact sets differ from those which are not?
I think the terminology here is very carefully chosen.</description>
    </item>
    
    <item>
      <title>Instrumentals v/s Vocal Music</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/instrumental/</link>
      <pubDate>Sun, 28 Jul 2019 16:02:49 -0400</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/instrumental/</guid>
      <description>I often talk to friends about music and musical preferences. This post is inspired by one such theme which often finds its way in most of these conversations: instrumental music v/s vocal music. Or more precisely, why listen to instrumental, or plain music, when you can have vocals accompanying the music.
This post is not from a musical perspective, but rather to emphasize on the entirely separate form of beauty inherent in instrumental music.</description>
    </item>
    
    <item>
      <title>Point Estimate</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/pointestimate/</link>
      <pubDate>Wed, 24 Jul 2019 01:34:25 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/pointestimate/</guid>
      <description>Point estimation problem A generic point estimation problem goes like this: Consider a random variable \(x\sim f(x;\theta)\) with the parameter \(\theta\in\Omega\). Here \(f(x;\theta)\) corresponds to a family of distributions rather than a single probability distribution. We are interested in finding a point estimate to the parameter \(\theta\). In order to do that, we draw a random sample with \(n\) realizations of the random variable \(x\) as \(\tilde{X}=\{x_1=X_1,x_2=X_2,\cdots, x_n=X_n\}\). In shorthand, this realization from the \(n\) experiments of the given family of distribution is also written as simply \(\{X_1,X_2,\cdots,X_n\}\).</description>
    </item>
    
  </channel>
</rss>