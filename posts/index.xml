<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Omanshu&#39;s blog</title>
    <link>http://omanshuthapliyal.github.io/blog/posts/</link>
    <description>Recent content in Posts on Omanshu&#39;s blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 18 Aug 2019 22:36:00 +0530</lastBuildDate>
    
	<atom:link href="http://omanshuthapliyal.github.io/blog/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ML SoTA Resources</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/ml-sota/</link>
      <pubDate>Sun, 18 Aug 2019 22:36:00 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/ml-sota/</guid>
      <description>The internet is filled with machine learning resources, and one of the most annoying things about them is the sheer volume. There are many attempts at making compilations of papers, code, and current status quo in the vastly active, and fast paced field. This post is to serve as a collection of my own where I will only post state of the art in machine learning.
Most of these links are updated frequently and maintained by the community, and I have collected these only for reference.</description>
    </item>
    
    <item>
      <title>But why is Compactness important?</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/compactness2/</link>
      <pubDate>Thu, 15 Aug 2019 01:34:25 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/compactness2/</guid>
      <description>In my last post I touched upon the intuition behind topological compactness. We as engineers often hear about the word &#39;compact&#39; as a soft gatekeeping tool from doing serious mathematics. In this post we see why the understanding is very important for doing any mathematics, especially as engineers.
Recall the open cover definition of a compact set as the existence of a finite open subcover for any given open cover of the set.</description>
    </item>
    
    <item>
      <title>Compactness</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/compactness/</link>
      <pubDate>Sat, 10 Aug 2019 15:44:20 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/compactness/</guid>
      <description>This is a non-mathematical note on what I understand about compactness and what it means for a set or a space to be compact. The open cover definition is one that can be found in any textbook, but what does it mean for a set to be compact? Why are such sets called compact? And how do compact sets differ from those which are not?
I think the terminology here is very carefully chosen.</description>
    </item>
    
    <item>
      <title>Instrumentals v/s Vocal Music</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/instrumental/</link>
      <pubDate>Sun, 28 Jul 2019 16:02:49 -0400</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/instrumental/</guid>
      <description>I often talk to friends about music and musical preferences. This post is inspired by one such theme which often finds its way in most of these conversations: instrumental music v/s vocal music. Or more precisely, why listen to instrumental, or plain music, when you can have vocals accompanying the music.
This post is not from a musical perspective, but rather to emphasize on the entirely separate form of beauty inherent in instrumental music.</description>
    </item>
    
    <item>
      <title>Point Estimate</title>
      <link>http://omanshuthapliyal.github.io/blog/posts/pointestimate/</link>
      <pubDate>Wed, 24 Jul 2019 01:34:25 +0530</pubDate>
      
      <guid>http://omanshuthapliyal.github.io/blog/posts/pointestimate/</guid>
      <description>Point estimation problem A generic point estimation problem goes like this: Consider a random variable \(x\sim f(x;\theta)\) with the parameter \(\theta\in\Omega\). Here \(f(x;\theta)\) corresponds to a family of distributions rather than a single probability distribution. We are interested in finding a point estimate to the parameter \(\theta\). In order to do that, we draw a random sample with \(n\) realizations of the random variable \(x\) as \(\tilde{X}=\{x_1=X_1,x_2=X_2,\cdots, x_n=X_n\}\). In shorthand, this realization from the \(n\) experiments of the given family of distribution is also written as simply \(\{X_1,X_2,\cdots,X_n\}\).</description>
    </item>
    
  </channel>
</rss>